{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/Users//Library/Jupyter/kernels/myenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = \"£££\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(url: str):\n",
    "    headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    r = requests.get(url, headers=headers)\n",
    "    if r.status_code == 200:\n",
    "        return r.text\n",
    "    else:\n",
    "        print(r.status_code)\n",
    "        return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()  \n",
    "driver.get(\"https://en.wikipedia.org/wiki/Christopher_Nolan\")\n",
    "page_content = driver.page_source\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page_content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(test_result, 'html.parser')\n",
    "page_content = {}\n",
    "headings = soup.find_all(['h2', 'h3', 'h4'])\n",
    "\n",
    "for heading in headings:\n",
    "    title = heading.get_text(strip=True)\n",
    "    \n",
    "    if title == \"Contents\":\n",
    "        continue\n",
    "    \n",
    "    content = []\n",
    "    next_element = heading.find_next()\n",
    "    while next_element:\n",
    "        if next_element.name in ['h2', 'h3', 'h4']:\n",
    "            break\n",
    "        \n",
    "        if next_element.name == 'div' and 'toc' in next_element.get('class', []):\n",
    "            next_element = next_element.find_next()\n",
    "            continue\n",
    "        \n",
    "        if next_element.name in ['p', 'ul', 'ol', 'table']:\n",
    "            content.append(next_element.get_text(strip=True))\n",
    "        \n",
    "        next_element = next_element.find_next()\n",
    "    \n",
    "    page_content[title] = content\n",
    "\n",
    "def save_print_content(page_content, output_dir, filename=\"Christopher_Nolan.txt\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    file_path = os.path.join(output_dir, filename)\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for title, content in page_content.items():\n",
    "            file.write(f\"## {title} ##\\n\")\n",
    "            file.write(\"\\n\".join(content) + \"\\n\")\n",
    "            file.write(\"\\n---\\n\")\n",
    "file_path = \"/Users//Desktop/Christopher_Nolan.txt\"\n",
    "print(f\"Saved: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(url, output_dir):\n",
    "    html_content = fetch_page(url)\n",
    "    \n",
    "    parsed_content = parse_page(html_content)\n",
    "    \n",
    "    save_print_content(parsed_content, output_dir)\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Christopher_Nolan\"\n",
    "output_dir = \"/Users//Desktop\"  \n",
    "\n",
    "main(url, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/Users//Documents\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Page fetched successfully!\")\n",
    "        return response.text\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch page: {url}\")\n",
    "\n",
    "\n",
    "def parse_page(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    print(\"Page parsed successfully!\")\n",
    "    \n",
    "  \n",
    "    page_content = {}\n",
    "\n",
    "   \n",
    "    headings = soup.find_all(['h2', 'h3', 'h4'])\n",
    "    print(f\"Found {len(headings)} headings.\")\n",
    "\n",
    "    for heading in headings:\n",
    "     \n",
    "        title = heading.get_text(strip=True)\n",
    "        print(f\"Processing heading: {title}\")\n",
    "        \n",
    "       \n",
    "        if title == \"Contents\":\n",
    "            continue\n",
    "        \n",
    "    \n",
    "        content = []\n",
    "        \n",
    "        \n",
    "        next_element = heading.find_next()\n",
    "        while next_element:\n",
    "            \n",
    "            if next_element.name in ['h2', 'h3', 'h4']:\n",
    "                break\n",
    "            \n",
    "           \n",
    "            if next_element.name == 'div' and 'toc' in next_element.get('class', []):\n",
    "                next_element = next_element.find_next()\n",
    "                continue\n",
    "            \n",
    "           \n",
    "            if next_element.name in ['p', 'ul', 'ol', 'table']:\n",
    "                content.append(next_element.get_text(strip=True))\n",
    "            \n",
    "            \n",
    "            next_element = next_element.find_next()\n",
    "        \n",
    "      \n",
    "        page_content[title] = content\n",
    "\n",
    "    return page_content\n",
    "\n",
    "\n",
    "def save_print_content(page_content, output_dir, filename=\"Christopher_Nolan.txt\"):\n",
    "  \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "   \n",
    "    file_path = os.path.join(output_dir, filename)\n",
    "    print(f\"File path: {file_path}\")\n",
    "    \n",
    "   \n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for title, content in page_content.items():\n",
    "            file.write(f\"## {title} ##\\n\")\n",
    "            file.write(\"\\n\".join(content) + \"\\n\")\n",
    "            file.write(\"\\n---\\n\")\n",
    "    \n",
    "   \n",
    "    print(f\"Saved: {file_path}\")\n",
    "\n",
    "\n",
    "def main(url, output_dir):\n",
    "   \n",
    "    html_content = fetch_page(url)\n",
    "    \n",
    "   \n",
    "    parsed_content = parse_page(html_content)\n",
    "    \n",
    "   \n",
    "    save_print_content(parsed_content, output_dir)\n",
    "\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Christopher_Nolan\"\n",
    "output_dir = \"/Users/V/Desktop\"  \n",
    "\n",
    "\n",
    "main(url, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christopher Nolan attended University College London (UCL).\n"
     ]
    }
   ],
   "source": [
    "uiversity_prompt = \"\"\"\n",
    "Question: \"Which university does Christopher Nolan attend?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_uiversity_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=uiversity_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_uiversity_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several possible answers to this question, as Christopher Nolan has received numerous awards throughout his career. Some of his major awards include:\n",
      "\n",
      "- Academy Award for Best Picture for producing \"The Departed\" (2006)\n",
      "- BAFTA Award for Best Director for \"Inception\" (2010)\n",
      "- Golden Globe Award for Best Motion Picture - Drama for producing \"Dunkirk\" (2017)\n",
      "- Directors Guild of America Award for Outstanding Directing - Feature Film for \"Inception\" (2010) and \"Dunkirk\" (2017)\n",
      "- Producers Guild of America Award for Outstanding Producer of Theatrical Motion Pictures for \"Inception\" (2010) and \"Dunkirk\" (2017)\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "award_prompt = \"\"\"\n",
    "Question: \"Which award did Christopher Nolan receive?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_award_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=award_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_award_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users//Desktop/Christopher_Nolan.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           paragraph\n",
      "0  ## Early life ##\\nChristopher Edward Nolan was...\n",
      "1                                  ---\\n## Career ##\n",
      "2  \\n---\\n## 1993–2003: Early career and breakthr...\n",
      "3  ---\\n## 2003–2013: Widespread recognition ##\\n...\n",
      "4  ---\\n## 2014–2019:Interstellar,Dunkirkand othe...\n"
     ]
    }
   ],
   "source": [
    "paragraphs = content.split(\"\\n\\n\")\n",
    "\n",
    "df = pd.DataFrame(paragraphs, columns=[\"paragraph\"])\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Early life Christopher Edward Nolan was born o...\n",
      "1                                                Career\n",
      "2     1993–2003: Early career and breakthrough After...\n",
      "3     2003–2013: Widespread recognition In early 200...\n",
      "4     2014–2019:Interstellar,Dunkirkand other activi...\n",
      "5     2020–present:TenetandOppenheimer Nolan's next ...\n",
      "6     Personal life and public image Nolan is marrie...\n",
      "7     Filmmaking style Nolan's films are largely cen...\n",
      "8     Recognition Nolan has made some of the most in...\n",
      "9     Filmography Following(1998)Memento(2000)Insomn...\n",
      "10    Awards and honours Nolan has been nominated fo...\n",
      "11    Notes Nolan has continued his collaboration wi...\n",
      "12    References \"Christopher Nolan, although a nati...\n",
      "13    Cited sources Blouin, Michael J. (2013). \"Diff...\n",
      "14    Further reading Belluomini, Lance (2021). \"Ten...\n",
      "15    External links Mediafrom CommonsQuotationsfrom...\n",
      "16                                                     \n",
      "17                                                     \n",
      "Name: paragraph, dtype: object\n",
      "                                            paragraph\n",
      "0   Early life Christopher Edward Nolan was born o...\n",
      "1   1993–2003: Early career and breakthrough After...\n",
      "2   2003–2013: Widespread recognition In early 200...\n",
      "3   2014–2019:Interstellar,Dunkirkand other activi...\n",
      "4   2020–present:TenetandOppenheimer Nolan's next ...\n",
      "5   Personal life and public image Nolan is marrie...\n",
      "6   Filmmaking style Nolan's films are largely cen...\n",
      "7   Recognition Nolan has made some of the most in...\n",
      "8   Filmography Following(1998)Memento(2000)Insomn...\n",
      "9   Awards and honours Nolan has been nominated fo...\n",
      "10  Notes Nolan has continued his collaboration wi...\n",
      "11  References \"Christopher Nolan, although a nati...\n",
      "12  Cited sources Blouin, Michael J. (2013). \"Diff...\n",
      "13  Further reading Belluomini, Lance (2021). \"Ten...\n",
      "14  External links Mediafrom CommonsQuotationsfrom...\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(paragraphs, columns=[\"paragraph\"])\n",
    "def clean_line(line):\n",
    "    line = line.replace(\"##\", \"\").replace(\"---\", \"\").replace(\"\\n\", \" \").replace(\"^\", \" \")\n",
    "    line = \" \".join(line.split())  \n",
    "    return line.strip()  \n",
    "df[\"paragraph\"] = df[\"paragraph\"].apply(clean_line)\n",
    "print(df[\"paragraph\"])\n",
    "df = df.drop([1, 16, 17])  \n",
    "\n",
    "df_cleaned = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df_cleaned )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            paragraph  token_count\n",
      "0   Early life Christopher Edward Nolan was born o...          615\n",
      "1   1993–2003: Early career and breakthrough After...         1493\n",
      "2   2003–2013: Widespread recognition In early 200...         1693\n",
      "3   2014–2019:Interstellar,Dunkirkand other activi...         1185\n",
      "4   2020–present:TenetandOppenheimer Nolan's next ...          831\n",
      "5   Personal life and public image Nolan is marrie...          165\n",
      "6   Filmmaking style Nolan's films are largely cen...          663\n",
      "7   Recognition Nolan has made some of the most in...         1027\n",
      "8   Filmography Following(1998)Memento(2000)Insomn...           80\n",
      "9   Awards and honours Nolan has been nominated fo...          316\n",
      "10  Notes Nolan has continued his collaboration wi...          162\n",
      "11  References \"Christopher Nolan, although a nati...         9184\n",
      "12  Cited sources Blouin, Michael J. (2013). \"Diff...         1338\n",
      "13  Further reading Belluomini, Lance (2021). \"Ten...          282\n",
      "14  External links Mediafrom CommonsQuotationsfrom...        54751\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df_cleaned[\"token_count\"] = df_cleaned[\"paragraph\"].apply(lambda x: len(encoding.encode(x)))\n",
    "print(df_cleaned[[\"paragraph\", \"token_count\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"cl100k_base\")\n",
    "\n",
    "\n",
    "max_tokens = 8192\n",
    "\n",
    "def split_text(text, max_tokens):\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        chunk = tokens[i:i + max_tokens]\n",
    "        chunks.append(encoding.decode(chunk))  \n",
    "    return chunks\n",
    "\n",
    "\n",
    "split_paragraphs = []\n",
    "original_indices = []  \n",
    "\n",
    "for index, text in enumerate(df[\"paragraph\"]):\n",
    "    if not text.strip():  \n",
    "        continue\n",
    "    chunks = split_text(text, max_tokens)\n",
    "    split_paragraphs.extend(chunks)\n",
    "    original_indices.extend([index] * len(chunks))  \n",
    "\n",
    "df_split = pd.DataFrame({\n",
    "    \"paragraph\": split_paragraphs,\n",
    "    \"original_index\": original_indices  \n",
    "})\n",
    "print(df_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "\n",
    "df_cleaned[\"token_count\"] = df_cleaned[\"paragraph\"].apply(lambda x: len(encoding.encode(x)))\n",
    "\n",
    "\n",
    "print(df_cleaned[[\"paragraph\", \"token_count\"]])\n",
    "\n",
    "\n",
    "max_tokens = 4000\n",
    "\n",
    "def split_text(text, max_tokens):\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        chunk = tokens[i:i + max_tokens]\n",
    "        chunks.append(encoding.decode(chunk))  \n",
    "    return chunks\n",
    "\n",
    "\n",
    "split_paragraphs = []\n",
    "original_indices = []  \n",
    "\n",
    "for index, text in enumerate(df_cleaned[\"paragraph\"]):\n",
    "    if not text.strip():  \n",
    "        continue\n",
    "    chunks = split_text(text, max_tokens)\n",
    "    split_paragraphs.extend(chunks)\n",
    "    original_indices.extend([index] * len(chunks))  \n",
    "\n",
    "\n",
    "df_split = pd.DataFrame({\n",
    "    \"paragraph\": split_paragraphs,\n",
    "    \"original_index\": original_indices  \n",
    "})\n",
    "\n",
    "\n",
    "print(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "\n",
    "for i in range(0, len(df_split), batch_size):\n",
    "    try:\n",
    "        batch_texts = df_split.iloc[i:i+batch_size][\"paragraph\"].tolist()\n",
    "        \n",
    "        response = openai.Embedding.create(\n",
    "            input=batch_texts,\n",
    "            engine=EMBEDDING_MODEL_NAME\n",
    "        )\n",
    "        \n",
    "        batch_embeddings = [data[\"embedding\"] for data in response[\"data\"]]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    except Exception as e:\n",
    "        print(f\"precessing {i} time{e}\")\n",
    "        continue  \n",
    "\n",
    "df_split[\"embeddings\"] = embeddings\n",
    "\n",
    "print(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    \"\"\"\n",
    "    Get the embedding vector for a given text using OpenAI's Embedding API.\n",
    "    \"\"\"\n",
    "    response = openai.Embedding.create(\n",
    "        input=[text],\n",
    "        engine=model\n",
    "    )\n",
    "    return response[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_rows_sorted_by_relevance(question, df_split):\n",
    "    \"\"\"\n",
    "    Sort rows in df_split by relevance to the question using cosine similarity.\n",
    "    \"\"\"\n",
    "    question_embedding = get_embedding(question) \n",
    "    \n",
    "    similarities = []\n",
    "    for embedding in df_split[\"embeddings\"]:\n",
    "        similarity = cosine_similarity([question_embedding], [embedding])[0][0]\n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    df_split[\"similarity\"] = similarities\n",
    "    \n",
    "    sorted_df = df_split.sort_values(by=\"similarity\", ascending=False)\n",
    "    \n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def create_prompt(question, df_split, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model.\n",
    "    \"\"\"\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                          len(tokenizer.encode(question))\n",
    "    \n",
    "    sorted_df = get_rows_sorted_by_relevance(question, df_split)\n",
    "    \n",
    "    context = []\n",
    "    for text in sorted_df[\"paragraph\"].values:  \n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break  \n",
    "\n",
    "   \n",
    "    prompt = prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below, and if the question\n",
      "can't be answered based on the context, say \"I don't know\"\n",
      "\n",
      "Context: \n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Question: When did Russia invade Ukraine?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(create_prompt(\"When did Russia invade Ukraine?\", df_split, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def answer_question(\n",
    "    question, df_split, max_prompt_tokens=1800, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = create_prompt(question, df_split, max_prompt_tokens)\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He received the British Film Institute Fellowship.\n"
     ]
    }
   ],
   "source": [
    "custom_award_answer = answer_question(\"Which award did Christopher Nolan receive?\", df_split)\n",
    "print(custom_award_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University College London (UCL).\n"
     ]
    }
   ],
   "source": [
    "custom_uni_answer = answer_question(\"Which university does Christopher Nolan attend?\", df_split)\n",
    "print(custom_uni_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma Thomas\n"
     ]
    }
   ],
   "source": [
    "custom_wife_answer = answer_question(\"who is  Christopher Nolan‘s wife?\", df_split)\n",
    "print(custom_wife_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When receiving his bachelor's degree, Nolan began working as a script reader, camera operator, and director of corporate and industrial films. Later, he worked on short films and attempted to make a feature film, but faced difficulty getting his projects off the ground.\n"
     ]
    }
   ],
   "source": [
    "custom_movie_answer = answer_question(\"what job is Christopher Nolan work during 1993–2003 ?\", df_split)\n",
    "print(custom_movie_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Which award did Christopher Nolan receive?\n",
      "Original Answer: There are several possible answers to this question, as Christopher Nolan has received numerous awards throughout his career. Some of his major awards include:\n",
      "\n",
      "- Academy Award for Best Picture for producing \"The Departed\" (2006)\n",
      "- BAFTA Award for Best Director for \"Inception\" (2010)\n",
      "- Golden Globe Award for Best Motion Picture - Drama for producing \"Dunkirk\" (2017)\n",
      "- Directors Guild of America Award for Outstanding Directing - Feature Film for \"Inception\" (2010) and \"Dunkirk\" (2017)\n",
      "- Producers Guild of America Award for Outstanding Producer of Theatrical Motion Pictures for \"Inception\" (2010) and \"Dunkirk\" (2017)\n",
      "-\n",
      "Custom Answer:   \n",
      "He received the British Film Institute Fellowship.\n",
      "\n",
      "Which university does Christopher Nolan attend?\n",
      "Original Answer: Christopher Nolan attended University College London (UCL).\n",
      "Custom Answer:   University College London (UCL).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Which award did Christopher Nolan receive?\n",
    "Original Answer: {initial_award_answer}\n",
    "Custom Answer:   \n",
    "{custom_award_answer}\n",
    "\n",
    "Which university does Christopher Nolan attend?\n",
    "Original Answer: {initial_uiversity_answer}\n",
    "Custom Answer:   {custom_uni_answer}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
